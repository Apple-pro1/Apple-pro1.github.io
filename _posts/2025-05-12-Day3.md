---
title: "AI Risk Classification System: Day 3"
date: 2025-05-12
categories: [AI Risk Classification System]
---

# Introduction

Today, I focused on developing code mainly for the high risk classification and transparency requirment method by researching Chapter 3 amd 4 of the [EU AI Act](https://artificialintelligenceact.eu/)

## Development Notes
Using the framework of the checkProhibitedUseCase method, I created a q&a yes/no system for the user to use to determine whether its AI system falls under the high-risk category. Chapter 3 of the EU AI Act classifies specific domains of high-risk AI systems and also includes a clause on whether an AI system is or is part of a safety component.

<img width="987" alt="Screenshot 2025-05-12 at 10 46 46 PM" src="https://github.com/user-attachments/assets/73ed7aea-4783-40dd-bffc-b7ccd627f7d2" />

Then, I moved on to complete the checkTransparencyRequirements method by using a similar outline and content from Chapter 4 from the EU AI Act.

<img width="842" alt="Screenshot 2025-05-12 at 10 49 55 PM" src="https://github.com/user-attachments/assets/1fb2db88-68a5-4f59-a8f0-3a1424f79483" />

To take advantage of modular programming, I also created a private static void method to display the results of the risk assessment. This method is called in the main method after classifying the AI system's level of risk to print a description accordingly.

<img width="741" alt="Screenshot 2025-05-12 at 10 51 14 PM" src="https://github.com/user-attachments/assets/98629435-edb4-473d-ada1-fa557c8140da" />

I tested the current code by entering inputs where I expect the program to output **Limited Risk** and the actual output matches the expected.
<img width="1063" alt="Screenshot 2025-05-12 at 10 59 18 PM" src="https://github.com/user-attachments/assets/12dacaf3-d530-4993-aed3-970e62cfd999" />

Next, I will be using ArrayLists to create a recommendation system that outputs system-specific compliance recommendations to meet the EU AI Act.


